---
title: "论文1酸感5.0"
author: "LX"
format: html
editor: visual
---

## \## 〇、项目概述与环境配置

\*\*核心策略：\*\* [1.]{.underline} \*\*数据源\*\*：仅使用 N=57 发现集，保证分析的一致性和统计效力。 [2.]{.underline} \*\*筛选逻辑\*\*：结合“统计显著性（Spearman/Kruskal-Wallis）”与“专家经验（16个核心指标）”。 [3.]{.underline} \*\*验证方式\*\*：通过聚类热图（Clustering Heatmap）验证核心指标是否能还原感官分类。

```{r}
#| label: setup
#| message: false
#| warning: false

# 1. 加载核心程序包
library(readr)      # 读取数据
library(dplyr)      # 数据清洗
library(tibble)     # 数据结构
library(tidyr)      # 数据整理
library(ggplot2)    # 绘图核心
library(ggpubr)     # 统计绘图扩展
library(pheatmap)   # 聚类热图
library(stringr)    # 字符串处理
library(showtext)   # 中文支持

# 2. 中文环境配置 (解决绘图乱码)
showtext_auto()
# 如果是 Windows，通常使用 SimHei 或 SimSun；Mac 使用 PingFang SC
# font_add("SimSun", "simsun.ttc") # 根据需要取消注释

# 3. 设置全局绘图主题
theme_set(theme_bw() + 
            theme(panel.grid = element_blank(),
                  plot.title = element_text(hjust = 0.5, face = "bold"),
                  axis.text = element_text(color = "black")))
```

## 一、数据加载与清洗 (Phase 1)

此处采用“映射表”机制，完美解决 R 语言对中文列名和特殊符号（如 `1-`, `()`）的不兼容问题。

```{r}
#| label: load-data
#| message: false

# 1. 读取数据
# 请确保 'data-57.csv' 在当前文件夹下
if (!file.exists("data-57.csv")) stop("错误：找不到 data-57.csv 文件！")
raw_data <- read_csv("data-57.csv", show_col_types = FALSE)

# 2. 构建“中文名 - 计算名”映射表
original_names <- colnames(raw_data)
clean_names <- make.names(original_names, unique = TRUE)

name_mapping <- tibble(
  Display_Name = original_names,      # 原名 (画图用)
  Computational_Name = clean_names    # 计算名 (统计用)
)

# 应用新列名
analysis_data <- raw_data
colnames(analysis_data) <- clean_names

# 3. 识别关键列与分组
# 假设: 第1列是样品ID，第2列是酸感得分
id_col <- clean_names[1]
score_col <- clean_names[2]

analysis_data <- analysis_data %>%
  rename(Sample_ID = all_of(id_col),
         Sourness_Score = all_of(score_col)) %>%
  # 按照 v5.0 的标准进行 4 级分组
  mutate(Group = cut(Sourness_Score, 
                     breaks = c(-Inf, 1.5, 3.0, 4.5, Inf),
                     labels = c("微酸 (Trace)", "稍酸 (Mild)", 
                                "酸 (Moderate)", "很酸 (Strong)"),
                     include.lowest = TRUE))

# 4. 提取候选化学物质列表 (排除 ID, Score, Group)
candidates <- name_mapping %>%
  filter(!Computational_Name %in% c(id_col, score_col, "Group"))

cat(">>> 数据准备就绪：\n")
cat("    样品数量:", nrow(analysis_data), "\n")
cat("    化学指标:", nrow(candidates), "个\n")
```

## 二、正态性和鲁棒性检验

```{r}
# ==========================================================
#  数据体检自测脚本 (No Black Box)
# ==========================================================
library(readr)
library(dplyr)
library(tidyr)
library(rstatix) # 用于正态性检验

# 1. 读取数据
df <- read_csv("data-57.csv") 
num_cols <- df %>% select(where(is.numeric)) %>% colnames()


# ----------------------------------------------------------
# A. 正态性检验 (Shapiro-Wilk 方法)
# 原理：P > 0.05 代表正态；P < 0.05 代表不正态
# ----------------------------------------------------------
normality_report <- data.frame(Variable = num_cols, P_value = NA, Is_Normal = NA)

for (i in 1:length(num_cols)) {
  col <- num_cols[i]
  vals <- df[[col]]
  
  # Shapiro检验要求样本量 3-5000
  if (length(na.omit(vals)) >= 3) {
    res <- shapiro_test(vals)
    normality_report$P_value[i] <- res$p.value
    normality_report$Is_Normal[i] <- ifelse(res$p.value > 0.05, "Yes", "No")
  }
}

# 保存正态性报告
View(normality_report)



# ----------------------------------------------------------
# B. 鲁棒离群值检测 (IQR / Boxplot Method)
# 原理：不看平均值，看中位数。
# 标准：超过 (Q3 + 3*IQR) 或 低于 (Q1 - 3*IQR) 为极端异常
# ----------------------------------------------------------
robust_report <- data.frame()

for (col in num_cols) {
  vals <- df[[col]]
  
  # 计算四分位数 (25% 和 75%)
  Q1 <- quantile(vals, 0.25, na.rm = TRUE)
  Q3 <- quantile(vals, 0.75, na.rm = TRUE)
  IQR_val <- Q3 - Q1
  median_val <- median(vals, na.rm = TRUE)
  
  # 定义极端异常的界限 (Extreme Outlier Limits)
  # 这里的 3 倍 IQR 相当于抓 "极度离谱" 的值
  # 如果想抓得严一点，可以把 3 改成 1.5
  upper_limit <- Q3 + 3 * IQR_val
  lower_limit <- Q1 - 3 * IQR_val
  
  # 找到异常值的位置
  bad_idx <- which(vals > upper_limit | vals < lower_limit)
  
  if (length(bad_idx) > 0) {
    temp <- data.frame(
      Variable = col,
      SampleID = df$'样品编号'[bad_idx],
      Value = vals[bad_idx],
      Median = median_val,
      # 计算偏离程度 (倍数)：(值 - 中位数) / IQR
      # 这个值越大，说明越离谱
      Deviation_Score = round((vals[bad_idx] - median_val) / IQR_val, 2)
    )
    # 过滤掉 Deviation_Score 无穷大或太小的情况
    temp <- temp %>% filter(is.finite(Deviation_Score) & abs(Deviation_Score) > 0)
    
    robust_report <- rbind(robust_report, temp)
  }
}

# 按离谱程度排序 (从大到小)
robust_report <- robust_report %>% arrange(desc(Deviation_Score))

# 查看
View(robust_report)
```

## 三、描述性统计

## 3.1酸感描述性统计

```{r}
# ==========================================================
# Phase 2: 描述性统计 (Descriptive Statistics) - 中英文混合旗舰版
# ==========================================================

# 1. 确保数据已加载
if (!exists("analysis_data")) stop("请先运行 Phase 1 加载数据！")

# 加载计算偏度峰度的包 (如果没有会自动使用替补函数)
if (!requireNamespace("e1071", quietly = TRUE)) {
  skewness <- function(x) { n <- length(x); (sum((x-mean(x))^3)/n)/(sum((x-mean(x))^2)/n)^1.5 }
  kurtosis <- function(x) { n <- length(x); n*sum((x-mean(x))^4)/(sum((x-mean(x))^2)^2)-3 }
} else { library(e1071) }

# 2. 定义全能统计函数 (按您要求的顺序排列)
get_full_summary <- function(x) {
  # --- 基础指标 (Basic) ---
  valid_n <- sum(!is.na(x))
  min_val <- min(x, na.rm = TRUE)
  max_val <- max(x, na.rm = TRUE)
  m       <- mean(x, na.rm = TRUE)
  s       <- sd(x, na.rm = TRUE)
  
  # --- 进阶/鲁棒指标 (Advanced/Robust) ---
  med     <- median(x, na.rm = TRUE)
  q1      <- quantile(x, 0.25, na.rm = TRUE)
  q3      <- quantile(x, 0.75, na.rm = TRUE)
  cv      <- (s / m) * 100
  
  # --- 形状指标 (Shape) ---
  skew    <- skewness(x, na.rm = TRUE)
  kurt    <- kurtosis(x, na.rm = TRUE)
  norm_p  <- if(valid_n > 3 && valid_n < 5000) shapiro.test(x)$p.value else NA
  
  # --- 整理成一行，列名采用中英文混合 ---
  data.frame(
    # 1. 基础信息
    `样本量 (N)`           = valid_n,
    `最小值 (Min)`         = sprintf("%.2f", min_val),
    `最大值 (Max)`         = sprintf("%.2f", max_val),
    `均值 ± 标准差 (Mean ± SD)` = paste0(sprintf("%.2f", m), " ± ", sprintf("%.2f", s)),
    
    # 2. 鲁棒指标 (非正态推荐用这个)
    # 格式：中位数 (下四分位, 上四分位)
    `中位数 (Median) (Q1, Q3)` = paste0(sprintf("%.2f", med), " (", sprintf("%.2f", q1), ", ", sprintf("%.2f", q3), ")"),
    
    # 3. 变异与形状
    `变异系数 (CV %)`      = sprintf("%.2f", cv),
    `偏度 (Skewness)`      = sprintf("%.2f", skew),
    `峰度 (Kurtosis)`      = sprintf("%.2f", kurt),
    `正态性 P值 (Shapiro P)` = sprintf("%.3f", norm_p),
    
    check.names = FALSE
  )
}

# 3. 计算“整体 (Total)”
total_stats <- get_full_summary(analysis_data$Sourness_Score)
row.names(total_stats) <- "总体 (Total N=57)"

# 4. 计算“各分组 (By Group)”
group_stats <- analysis_data %>%
  group_by(Group) %>%
  summarise(Data = list(Sourness_Score), .groups = "drop") %>%
  rowwise() %>%
  mutate(Stats = list(get_full_summary(unlist(Data)))) %>%
  unnest(Stats) %>%
  select(-Data)

# 处理行名
group_stats_df <- as.data.frame(group_stats)
rownames(group_stats_df) <- group_stats_df$Group
group_stats_df <- group_stats_df %>% select(-Group)

# 5. 合并并输出
final_table1 <- rbind(total_stats, group_stats_df)
final_table1 <- final_table1 %>% tibble::rownames_to_column("分组 (Group)")

# 保存
write_csv(final_table1, "Table1_Descriptive_Statistics_Mixed.csv")

cat(">>> 描述性统计表 (Table 1) 已生成！\n")
cat(">>> 列顺序已调整：N -> Min/Max -> Mean -> Median(Robust) -> CV -> Skew/Kurt\n")

# 展示表格
knitr::kable(final_table1, caption = "表1：酸感得分描述性统计 (Table 1: Descriptive Statistics of Sourness Scores)")
```

## 3.2 化学指标变异系数图

```{r}
# ==========================================================
# 2.1 补充图表：化学指标变异系数 (CV) 分布图
# ==========================================================
library(ggplot2)
library(dplyr)
library(tidyr)

# 1. 准备数据
# 假设 analysis_data 已经加载
# 我们需要剔除 metadata (Sample_ID, Group, Sourness_Score 等)
# 只保留那 100 多个化学指标
# 这里假设前 4 列是基本信息，第 5 列开始是化学指标
# 【注意】请根据你的实际数据调整 select 的排除项
chem_data <- analysis_data %>%
  select(-Sample_ID, -Group, -Sourness_Score) %>%
  select(where(is.numeric)) # 确保只选数值列

# 2. 计算每个指标的 CV (变异系数)
cv_stats <- chem_data %>%
  summarise(across(everything(), list(
    Mean = ~mean(., na.rm = TRUE),
    SD = ~sd(., na.rm = TRUE)
  ))) %>%
  pivot_longer(cols = everything(), 
               names_to = c("Feature", "Stat"), 
               names_sep = "_") %>%
  pivot_wider(names_from = Stat, values_from = value) %>%
  mutate(
    CV = (SD / Mean) * 100
  ) %>%
  arrange(CV) %>% # 按 CV 从小到大排序
  mutate(
    Rank = row_number(), # 生成排名 1, 2, 3...
    Is_High_Var = ifelse(CV > 20, "High Variation (>20%)", "Low Variation") # 设定一个阈值分类
  )

# 3. 绘图 (S型排位散点图)
p_cv <- ggplot(cv_stats, aes(x = Rank, y = CV)) +
  # 画点，颜色根据 CV 大小渐变
  geom_point(aes(color = CV), size = 2.5, alpha = 0.8) +
  
  # 添加 20% 阈值线
  geom_hline(yintercept = 20, linetype = "dashed", color = "red", alpha = 0.6) +
  annotate("text", x = 5, y = 25, label = "Threshold: CV = 20%", color = "red", hjust = 0, size = 3.5) +
  
  # 颜色设置
  scale_color_gradient(low = "#4DBBD5", high = "#E64B35", name = "CV (%)") +
  
  # 标注几个 CV 特别大的关键物质 (比如 Top 3)
  geom_text(data = tail(cv_stats, 3), 
            aes(label = Feature), 
            hjust = 1.1, vjust = 0.5, size = 3, color = "black") +
  
  # 主题美化
  theme_bw() +
  labs(
    
    subtitle = paste0("Total ", nrow(cv_stats), " Indicators | Mean CV: ", round(mean(cv_stats$CV), 1), "%"),
    x = "化学指标",
    y = "变异系数 (%)"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    legend.position = "right"
  )

# 4. 保存
ggsave("Figure1_Chemical_CV_Distribution.PDF", p_cv, width = 8, height = 5, dpi = 300)

print(p_cv)

# 5. 生成论文写作素材 (直接算出来填空)
cat(">>> 论文写作素材 (2.1节):\n")
cat(paste0("本研究共检测了 ", nrow(cv_stats), " 种化学成分。\n"))
cat(paste0("统计分析显示，化学成分的变异系数 (CV) 范围为 ", round(min(cv_stats$CV),1), "% 至 ", round(max(cv_stats$CV),1), "%。\n"))
cat(paste0("其中，", sum(cv_stats$CV > 20), " 个指标 (占比 ", round(sum(cv_stats$CV > 20)/nrow(cv_stats)*100, 1), "%) 的 CV 值大于 20%。\n"))
```

## 四、差异性分析

```{r}
# ==========================================================
# Phase 2: 差异性分析 (Kruskal-Wallis) - 优化增强版
# ==========================================================
library(dplyr)
library(readr)
library(tidyr)

# 1. 检查数据 (保持不变)
if (!exists("analysis_data") || !exists("name_mapping") || !exists("candidates")) {
  stop("数据缺失！请先选中并运行 Phase 1 的全部代码。")
}

cat(">>> 开始进行 Kruskal-Wallis 差异性筛选...\n")

# 2. 优化：使用 lapply 替代 for 循环 (效率更高，逻辑更整洁)
target_vars <- candidates$Computational_Name 

kw_list <- lapply(target_vars, function(var) {
  
  # 提取数据
  test_data <- analysis_data %>% 
    select(Group, all_of(var)) %>% 
    na.omit()
  
  # 判断数据量
  if (nrow(test_data) > 3 && n_distinct(test_data$Group) > 1) {
    
    # 核心检验
    kw_test <- kruskal.test(as.formula(paste(var, "~ Group")), data = test_data)
    
    # 返回一行结果
    return(data.frame(
      Computational_Name = var,
      P_Value = kw_test$p.value,
      Statistic = kw_test$statistic,
      Note = "OK", # 标记状态
      stringsAsFactors = FALSE
    ))
  } else {
    # 优化点：记录数据不足的指标，防止它们莫名其妙消失
    return(data.frame(
      Computational_Name = var,
      P_Value = NA,
      Statistic = NA,
      Note = "Data insufficient", # 标记原因
      stringsAsFactors = FALSE
    ))
  }
})

# 合并列表为数据框
kw_results <- bind_rows(kw_list)

# 3. 结果整理 (增加多重检验校正)
final_results <- kw_results %>%
  left_join(name_mapping, by = "Computational_Name") %>%
  
  # 过滤掉无法计算的行 (可选，看你想不想在表里保留它们)
  filter(!is.na(P_Value)) %>%
  
  arrange(P_Value) %>%
  
  mutate(
    # 优化点：增加 FDR 校正 P 值 (BH法)
    P_Adj = p.adjust(P_Value, method = "BH"),
    
    # 显著性标记 (这里依然保留原始P值标记，你可以根据严格程度改成用 P_Adj)
    Significance = case_when(
      P_Value < 0.001 ~ "***",
      P_Value < 0.01  ~ "**",
      P_Value < 0.05  ~ "*",
      TRUE            ~ "ns"
    )
  ) %>%
  
  select(Display_Name, P_Value, P_Adj, Significance, Statistic, Computational_Name)

# 4. 筛选显著物质
candidates_significant <- final_results %>% filter(P_Value < 0.05)

# 5. 保存
write_csv(final_results, "2_Diff_Analysis_All_Results.csv")
write_csv(candidates_significant, "2_Diff_Analysis_Sig_Candidates.csv")

# 6. 打印战报
cat("------------------------------------------------\n")
cat("差异分析完成！\n")
cat("共分析指标:", nrow(kw_results), "个\n")
cat("有效计算指标:", nrow(final_results), "个\n")
cat("显著差异指标 (P < 0.05):", nrow(candidates_significant), "个\n")
cat("------------------------------------------------\n")
print(head(candidates_significant[, 1:4], 10))
```

## 五、相关性分析

```{r}
# ==========================================================
# Phase 3: 差异物质的相关性分析与重点可视化
# ==========================================================
library(dplyr)
library(ggplot2)
library(readr)
library(stringr)

# 1. 环境检查
if (!exists("analysis_data")) stop("请先运行 Phase 1 加载数据！")

# 2. 读取 Phase 2 的“幸存者名单”
# 逻辑：只分析在 Phase 2 中差异显著的物质，这是严格的漏斗
if (!file.exists("2_Diff_Analysis_Sig_Candidates.csv")) {
  stop("找不到 Phase 2 的结果文件，请先运行差异分析。")
}
diff_sig_data <- read_csv("2_Diff_Analysis_Sig_Candidates.csv", show_col_types = FALSE)
target_vars <- diff_sig_data$Computational_Name

cat(">>> Phase 3 分析范围已锁定：仅分析 Phase 2 显著的", length(target_vars), "个物质。\n")

# ----------------------------------------------------------
# Part A: 全量计算 (生成大表)
# ----------------------------------------------------------
get_stars <- function(p) {
  if (is.na(p)) return("")
  if (p < 0.001) return("***")
  if (p < 0.01) return("**")
  if (p < 0.05) return("*")
  return("") 
}

cor_results <- data.frame()

for (comp_name in target_vars) {
  # 找回中文名
  if (exists("name_mapping")) {
    disp_name <- name_mapping$Display_Name[name_mapping$Computational_Name == comp_name]
  } else {
    disp_name <- comp_name
  }
  
  if (comp_name %in% colnames(analysis_data)) {
    # 计算 Spearman 相关性
    res <- cor.test(analysis_data[[comp_name]], analysis_data$Sourness_Score, 
                    method = "spearman", exact = FALSE)
    
    cor_results <- rbind(cor_results, data.frame(
      Display_Name = disp_name,
      Computational_Name = comp_name,
      Rho = res$estimate,
      P_Value = res$p.value,
      Stars = get_stars(res$p.value),
      Type = ifelse(res$estimate > 0, "Positive (Promoting)", "Negative (Suppressing)")
    ))
  }
}

# 按相关性绝对值排序，生成完整的大表
full_table <- cor_results %>% arrange(desc(abs(Rho)))

# 保存大表 (这就是你稍后要发给我看的东西)
write_csv(full_table, "3_Phase3_Correlation_All_Significant.csv")

cat(">>> Part A 完成！所有显著物质的相关性已算出。\n")
cat(">>> 请查看文件 '3_Phase3_Correlation_All_Significant.csv'\n")


# ==========================================================
# Phase 3 Part B: 精选绘图 (高清大字版)
# ==========================================================

# 1. 读取你刚才生成的大表
full_table <- read_csv("3_Phase3_Correlation_All_Significant.csv", show_col_types = FALSE)

# 2. 定义专家精选名单 (根据你的数据量身定制)
# 这些物质都在你的显著列表里，且机理明确
expert_selection <- c(
  # --- 正向促进 (Promoters) ---
  "绿原酸", "芸香苷",         # 多酚 (Top 1 & 2)
  "蔗糖", "葡萄糖", "总糖",   # 糖类 (注意：你的数据里糖是正相关，这点很特别，值得讨论)
  "DDMP",                     # 美拉德产物
  "乙酸", "丙酸",             # 挥发酸 (直接酸感)
  "糠醛",                     # 烘烤香
  
  # --- 负向抑制 (Suppressors) ---
  "异戊酰胺",                 # 相关性极高的抑制物
  "草酸", "柠檬酸",           # 非挥发酸 (起缓冲作用，负相关)
  "尼古丁", "总氮",           # 碱类 (中和作用)
  "3-甲基吲哚", "吡咯",       # 杂气成分
  "3-甲基戊酸"                # 汗味酸
)

# 3. 提取数据
plot_data <- full_table %>%
  filter(Display_Name %in% expert_selection) %>%
  arrange(desc(abs(Rho)))

# 4. 绘图 (大字号优化版)
library(stringr) # 确保加载

# 名字换行
plot_data$Display_Name <- str_wrap(plot_data$Display_Name, width = 20)

p <- ggplot(plot_data, aes(x = reorder(Display_Name, Rho), y = Rho)) +
  # 画棒棒糖的杆
  geom_segment(aes(xend = reorder(Display_Name, Rho), y = 0, yend = Rho, color = Type), 
               linewidth = 1.5) + # 线条加粗
  
  # 画棒棒糖的头
  geom_point(aes(color = Type, size = abs(Rho)), alpha = 0.9) +
  
  # 标星号 (字号调大 size=6)
  geom_text(aes(label = Stars, y = Rho), 
            nudge_y = ifelse(plot_data$Rho > 0, 0.08, -0.08),
            vjust = 0.75, size = 6, fontface = "bold") +
  
  # 颜色设置
  scale_color_manual(values = c("Positive (Promoting)" = "#E41A1C", 
                                "Negative (Suppressing)" = "#377EB8")) +
  
  coord_flip() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray60", linewidth = 0.8) +
  
  labs(title = "Key Sourness-Correlated Biomarkers",
       subtitle = "Selected representative compounds (P < 0.05)",
       x = "", y = "Spearman Correlation (Rho)",
       color = "Mechanism", size = "Strength") +
  
  # --- 核心修改：全局字号放大 ---
  theme_bw(base_size = 14) + # 基准字号设为 14
  theme(
    plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
    plot.subtitle = element_text(size = 14, hjust = 0.5, color = "gray40"),
    
    # Y轴物质名：加粗、放大
    axis.text.y = element_text(size = 14, face = "bold", color = "black"),
    # X轴刻度：放大
    axis.text.x = element_text(size = 12, color = "black"),
    
    # 图例设置
    legend.position = "bottom",
    legend.text = element_text(size = 12),
    legend.title = element_text(size = 13, face = "bold"),
    
    # 边距微调，防止字被切掉
    plot.margin = margin(t = 10, r = 20, b = 10, l = 10, unit = "pt")
  )

# 5. 保存 (调整宽高比)
# 宽度设宽一点，给Y轴文字留空间
print(p)

# ==========================================================
# 独立导出模块：解决字号小和中文乱码问题
#万能 PDF (解决中文乱码)
# 技巧：使用 device = cairo_pdf，这是 R 处理中文 PDF 的神器
# ----------------------------------------------------------
ggsave("3_Expert_Correlation_Lollipop.pdf", p, 
       width = 8, height = 8, 
       device = cairo_pdf,     # 【关键】使用 cairo 引擎渲染中文
       family = "sans")        # 防止字体报错

cat(">>> PDF 已导出。\n")


```

```{r}

```

你在看这张图的时候，可能会发现一个**非常有趣且反常识**的现象，这正是你论文的亮点：

1.  **糖类（总糖、蔗糖、葡萄糖）是正相关（Rho \> 0）**：

    -   *常规认知*：糖通常掩盖酸味（负相关）。

    -   *你的数据*：糖越高，酸感越强。

    -   *解释方向*：这可能说明在你的加热卷烟体系中，**“糖酸共存”**。可能是糖在加热过程中降解产生了酸（如甲酸、乙酸、乙酰丙酸等），或者高糖样品本身就是高等级烟叶，其内含物（包括酸）整体都丰富。这是一个非常好的 Discussion 切入点。

2.  **乙酸 vs. 柠檬酸**：

    -   **乙酸（正相关）**：直接提供刺激性酸感。

    -   **柠檬酸/草酸（负相关）**：作为非挥发性有机酸，它们可能更多起到缓冲 pH 值的效果，使烟气柔和，反而降低了那种“尖刺”的酸感评分。

```{r}
# ==========================================================
# Phase 3 Part C: 高端期刊矢量图导出 (SVG/EPS)
# ==========================================================

# 1. 加载矢量图专用包
# 如果没安装，请先运行: install.packages("svglite")
if (!requireNamespace("svglite", quietly = TRUE)) {
  install.packages("svglite")
}
library(svglite)
library(ggplot2) # 确保加载

# 2. 检查图是否存在
if (!exists("p")) {
  stop("错误：找不到绘图对象 'p'。请先运行 Phase 3 Part B 生成图片。")
}

cat(">>> 开始导出矢量图...\n")

# ----------------------------------------------------------
# 格式 A: SVG (Scalable Vector Graphics) - 最推荐
# 优势：体积小，网页友好，支持透明度，Illustrator 可完美编辑
# ----------------------------------------------------------
ggsave("3_Expert_Correlation_Lollipop.svg", p, 
       width = 8, height = 8, 
       device = "svg")  # 显式指定设备

cat(">>> SVG 格式已导出：3_Expert_Correlation_Lollipop.svg\n")

# ----------------------------------------------------------
# 格式 B: EPS (Encapsulated PostScript) - 老牌期刊常用
# 注意：EPS 不支持半透明 (alpha)，如果你的图里有 alpha=0.9，
# 可能会被强制转成实色或栅格化。
# ----------------------------------------------------------
# ggsave("3_Expert_Correlation_Lollipop.eps", p, 
#        width = 8, height = 8, 
#        device = cairo_ps,  # 使用 cairo_ps 引擎以支持部分特殊字符
#        fallback_resolution = 300)

# cat(">>> EPS 格式已导出。\n")


```
